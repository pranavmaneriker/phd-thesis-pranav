
The success of neural networks and the advent of specialized hardware such as GPUs has led to larger models with increasingly large unstructured datasets in machine learning.
Curating and assembling a high-quality large dataset is a time-consuming and expensive process.
Further, training models on these datasets requires expensive computing resources.
Some of these issues are alleviated with the advent of paradigms such as self-supervised and transfer learning.
However, when the data continue to drift and change over time,
%, these paradigms are unable to adapt; 
models need to be periodically retrained to keep up.
Graph structures, both implicit and explicit, are ubiquitous in Natural Language Processing.
Implicit structures are derived from language morphology, syntax, and semantics and expressed using attributed tree graphs.
External structures capture world knowledge and semantics using knowledge graphs and ontologies.
Additionally, textual data may have associated metadata in external graphs, such as network structure for social media interactions.
In this proposal, we posit that an abundance of associated structural information is underutilized for scaling and adaptation.
The prevalence of these structures behooves us to utilize them to improvise, adapt, and overcome the challenges posed by scaling and drifts in data.

%I the role of graph structures in augmenting natural language processing and machine learning in order to make them adapt to changes in the underlying data over time. 
In our work, we focus on three directions in which to use these structures, viz. augmenting existing text models with structure, exploring the role of structure in creating adversarial testing samples, and structured-enhanced monitoring of the performance of models over time.
The first direction that we explore is the impact of incorporating structure into text representation learning pipelines.
In our first contribution, we study how the implicit structure of text data (here, URLs) can be used to design domain-specific losses and adversarial attacks to build a state-of-the-art system for phishing URL detection.
This work comprehensively analyzes transformer models on the phishing URL detection task.
We consider the standard masked language model and additional domain-specific pre-training tasks and compare these models to fine-tuned transformer models.
Our model improves over the best baseline over a range of low false positive rates.
We then demonstrate how these models can be more robust by using adversaries constructed from benign URLs using a domain-informed attack scenario. 
In both fine-tuning and adversarial attacks, the underlying syntax of URLs serves as the structure that enables us to build a robust model.


The second direction of work we study is the role of intrinsic structure in the visualization and analysis of the fairness of machine learning models.
Specifically, we study the syntax of commonly used fairness metrics 
Our contribution improves the probabilistic guarantees for such grammars in an interactive and online setting.
We construct a novel visualization mechanism that can be used to investigate the context of reported fairness violations and guide users toward meaningful and compliant fairness specifications.
Finally, in our third contribution, we study author identification on darkweb forums.
Our work demonstrates that it is possible to appropriately intermingle graph representation learning with textual representations to utilize the orthogonal signals from each and improve AuthorID across time-disjoint task settings.
We develop a novel stylometry-based multitask learning approach for natural language and model interactions using graph embeddings to construct low-dimensional representations of short episodes of user activity for authorship attribution. 
We comprehensively evaluate our methods across four darkweb forums demonstrating their efficacy over the state-of-the-art, with a lift of up to 2.5X on Mean Retrieval Rank and 2X on Recall@10.

%For our second direction of work, we study the task of extracting a structured representation of unstructured data in evolving scenarios. 

We hope to explore and expand our existing work in these directions in future work. 
First, we aim to explore two aspects of augmentation in the stylometry setting - data scale and model explainability. 
The real-world application for stylometry pertains to content moderation. 
In these scenarios, models must be able to adapt to large-scale textual corpora.
In addition, when making a moderation decision (say, banning a user), a human must provide a justification.
Existing stylometry explanation techniques rely on general text explainability approaches. 
We aim to expand on our previous explorations to provide bespoke methods beyond gradient-based attribution approaches.
We also aim to extend our techniques for estimating the fairness of machine learning models to more general settings.

\endinput