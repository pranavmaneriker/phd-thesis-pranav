\chapter{Conformal Prediction and Fairness in Graph Structured Data}
\label{chp:graphConformal}
In the previous chapter, confidence intervals were used to generate online, anytime-valid bounds for the outputs associated with different decision-making models.
However, confidence intervals require a strong assumption on the data-generating distribution at test time i.e, independent and identically distributed (i.i.d) data.
For graph structured data, the edges between different nodes denote potential dependencies between the nodes.
Thus, the i.i.d assumption is violated, and the confidence intervals are no longer valid.
In this chapter, we will discuss conformal prediction, a method that provides valid confidence intervals for graph structured data with a weaker assumption - exchangeability.
While the estimates generated by these are no-longer online, anytime-valid, the strong guarantees provided by these methods can provide a foundation for understanding the uncertainty associated with the predictions in graph structured data.
In the first part of this chapter, we will discuss the theoretical underpinnings of conformal prediction and the tradeoffs associated with its application to graph structured data.
Following this, in the second part, we will conclude with a discussion of extending conformal prediction for studying the fairness of decision-making models trained for graph structured data.

\section{Understanding the Tradeoffs in Graph Conformal Prediction}

Conformal prediction has become increasingly popular as a method for quantifying the uncertainty associated with machine learning models. 
The computational efficiency of the inductive approach has made it the method du jour for building new methods for conformal prediction.
Recent work in graph uncertainty quantification has built upon this approach for conformal prediction on graphs.
The nascent nature of these explorations has lead to conflicting choices for implementations baselines and evaluation of approaches.
We critically analyze the choices made and describe the tradeoffs associated with existing graph conformal prediction work. 
Our theoretical and empirical results provide the rationale for our recommendations for future scholarship in graph conformal prediction.

\subsection{Introduction}
\input{graphConformal/benchmarking/introduction}

\subsection{Conformal Prediction}
\input{graphConformal/benchmarking/conformal_prediction}

\subsection{Applying Conformal Prediction to Graph Structured Data}
\input{graphConformal/benchmarking/conformal_to_graphs}

\subsection{Conformal Scores for Graphs}
\input{graphConformal/benchmarking/graph_conformal_scores.tex}


\section{Graph Models and Fairness through Conformal Prediction}
The standard formulation for conformal prediction (Theorem~\ref{thm:CP:coverage}) provides a score-based mechanism to control for miscoverage in the prediction sets.
However, when dealing with fairness, we may want to reason over guarantees over other expressions that involve the inputs, labels, and predictions.
Such guarantees can be considered as a form of thresholded risk Control.
In the conformal setting, the Learn Then Test~\citep{angelopoulos2021learn} and conformal risk control~\citep{angelopoulos2024conformal} frameworks provide a way to control for model risks for specific classes of risk functions.
In the following sections, we first describe each of these frameworks and their limitations, and then provide a mechanism to construct fairness guarantees using risk control over different population subgroups.
Note that we will describe the split CP version of each of these frameworks.

\subsection{Learn Then Test for Risk Control}
\input{graphConformal/fairness/learn_then_test}

\subsection{Conformal Risk Control}
\input{graphConformal/fairness/conformal_risk_control}

\subsection{Risk Control for Fairness}

\begin{subappendices}
    \input{graphConformal/benchmarking/appendix.tex}
\end{subappendices}
